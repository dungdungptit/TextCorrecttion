{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản ban đầu: I loev programing in Pythonn\n",
      "Văn bản đã sửa: I love programming in Pythonn\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Văn bản chứa lỗi chính tả\n",
    "text = \"I loev programing in Pythonn\"\n",
    "\n",
    "# Sử dụng TextBlob để sửa lỗi\n",
    "blob = TextBlob(text)\n",
    "corrected_text = blob.correct()\n",
    "\n",
    "print(\"Văn bản ban đầu:\", text)\n",
    "print(\"Văn bản đã sửa:\", corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản ban đầu: I loev programing in Pythonn\n",
      "Văn bản đã sửa: I loev programing in Pythonn\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Khởi tạo PySpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Văn bản chứa lỗi chính tả\n",
    "text = \"I loev programing in Pythonn\"\n",
    "words = text.split()\n",
    "\n",
    "# Sửa từng từ\n",
    "corrected_words = [spell.correction(word) if word in spell else word for word in words]\n",
    "corrected_text = \" \".join(corrected_words)\n",
    "\n",
    "print(\"Văn bản ban đầu:\", text)\n",
    "print(\"Văn bản đã sửa:\", corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản ban đầu: I can programming good in Python. It make me happy everyday.\n",
      "\n",
      "Lỗi phát hiện và gợi ý sửa:\n",
      "- Lỗi: MD_BASEFORM\n",
      "  Mô tả lỗi: Modal verbs like ‘can’ or ‘will’ require the following verb to be in its base form.\n",
      "  Từ/cụm từ sai: programming\n",
      "  Vị trí: 6 - 17\n",
      "  Gợi ý sửa: program, programme, be programming\n",
      "\n",
      "- Lỗi: IT_VBZ\n",
      "  Mô tả lỗi: After ‘It’, use the third-person verb form “makes”.\n",
      "  Từ/cụm từ sai: make\n",
      "  Vị trí: 37 - 41\n",
      "  Gợi ý sửa: makes\n",
      "\n",
      "- Lỗi: EVERYDAY_EVERY_DAY\n",
      "  Mô tả lỗi: ‘Everyday’ is an adjective. Did you mean “every day”?\n",
      "  Từ/cụm từ sai: everyday\n",
      "  Vị trí: 51 - 59\n",
      "  Gợi ý sửa: every day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "\n",
    "# Khởi tạo LanguageTool với ngôn ngữ tiếng Anh (en-US)\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Văn bản cần kiểm tra lỗi\n",
    "text = \"I can programming good in Python. It make me happy everyday.\"\n",
    "\n",
    "# Kiểm tra lỗi\n",
    "matches = tool.check(text)\n",
    "\n",
    "# In thông tin chi tiết về lỗi\n",
    "print(\"Văn bản ban đầu:\", text)\n",
    "print(\"\\nLỗi phát hiện và gợi ý sửa:\")\n",
    "for match in matches:\n",
    "    print(f\"- Lỗi: {match.ruleId}\")\n",
    "    print(f\"  Mô tả lỗi: {match.message}\")\n",
    "    print(f\"  Từ/cụm từ sai: {text[match.offset:match.offset + match.errorLength]}\")\n",
    "    print(f\"  Vị trí: {match.offset} - {match.offset + match.errorLength}\")\n",
    "    print(f\"  Gợi ý sửa: {', '.join(match.replacements)}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản ban đầu: I can programming good in Python. It make me happy everyday.\n",
      "Văn bản đã sửa: I can program good in Python. It makes me happy every day.\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "\n",
    "# Khởi tạo LanguageTool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Văn bản chứa lỗi\n",
    "text = \"I can programming good in Python. It make me happy everyday.\"\n",
    "\n",
    "# Sửa lỗi\n",
    "matches = tool.check(text)\n",
    "corrected_text = language_tool_python.utils.correct(text, matches)\n",
    "\n",
    "print(\"Văn bản ban đầu:\", text)\n",
    "print(\"Văn bản đã sửa:\", corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản ban đầu:\n",
      "I can programming good in Python. It make me happy everyday.\n",
      "\n",
      "Chi tiết lỗi phát hiện:\n",
      "\n",
      "Lỗi 1:\n",
      "- Mô tả lỗi: Modal verbs like ‘can’ or ‘will’ require the following verb to be in its base form.\n",
      "- Từ/cụm từ sai: 'programming'\n",
      "- Vị trí trong văn bản: 6 - 17\n",
      "- Gợi ý sửa: program, programme, be programming\n",
      "\n",
      "Lỗi 2:\n",
      "- Mô tả lỗi: After ‘It’, use the third-person verb form “makes”.\n",
      "- Từ/cụm từ sai: 'make'\n",
      "- Vị trí trong văn bản: 37 - 41\n",
      "- Gợi ý sửa: makes\n",
      "\n",
      "Lỗi 3:\n",
      "- Mô tả lỗi: ‘Everyday’ is an adjective. Did you mean “every day”?\n",
      "- Từ/cụm từ sai: 'everyday'\n",
      "- Vị trí trong văn bản: 51 - 59\n",
      "- Gợi ý sửa: every day\n",
      "\n",
      "Văn bản đã sửa:\n",
      "I can program good in Python. It makes me happy every day.\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "\n",
    "# Khởi tạo LanguageTool cho tiếng Anh (hoặc tiếng Việt với mã 'vi')\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Văn bản cần kiểm tra lỗi\n",
    "text = \"I can programming good in Python. It make me happy everyday.\"\n",
    "\n",
    "# Kiểm tra lỗi\n",
    "matches = tool.check(text)\n",
    "\n",
    "# Hiển thị chi tiết lỗi và gợi ý sửa\n",
    "print(\"Văn bản ban đầu:\")\n",
    "print(text)\n",
    "print(\"\\nChi tiết lỗi phát hiện:\")\n",
    "\n",
    "for i, match in enumerate(matches, start=1):\n",
    "    print(f\"\\nLỗi {i}:\")\n",
    "    print(f\"- Mô tả lỗi: {match.message}\")\n",
    "    print(f\"- Từ/cụm từ sai: '{text[match.offset:match.offset + match.errorLength]}'\")\n",
    "    print(f\"- Vị trí trong văn bản: {match.offset} - {match.offset + match.errorLength}\")\n",
    "    print(f\"- Gợi ý sửa: {', '.join(match.replacements) if match.replacements else 'Không có gợi ý'}\")\n",
    "\n",
    "# Tự động sửa lỗi trong văn bản\n",
    "corrected_text = language_tool_python.utils.correct(text, matches)\n",
    "\n",
    "print(\"\\nVăn bản đã sửa:\")\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu trúc câu và thông tin từ vựng:\n",
      "Token: \n",
      ", POS: SPACE, Lemma: \n",
      ", Dependency: dep\n",
      "Token: He, POS: PRON, Lemma: he, Dependency: nsubj\n",
      "Token: are, POS: AUX, Lemma: be, Dependency: ROOT\n",
      "Token: a, POS: DET, Lemma: a, Dependency: det\n",
      "Token: good, POS: ADJ, Lemma: good, Dependency: amod\n",
      "Token: boy, POS: NOUN, Lemma: boy, Dependency: attr\n",
      "Token: ., POS: PUNCT, Lemma: ., Dependency: punct\n",
      "Token: She, POS: PRON, Lemma: she, Dependency: nsubj\n",
      "Token: go, POS: VERB, Lemma: go, Dependency: ROOT\n",
      "Token: to, POS: ADP, Lemma: to, Dependency: prep\n",
      "Token: school, POS: NOUN, Lemma: school, Dependency: pobj\n",
      "Token: everyday, POS: ADV, Lemma: everyday, Dependency: npadvmod\n",
      "Token: ., POS: PUNCT, Lemma: ., Dependency: punct\n",
      "Token: \n",
      ", POS: SPACE, Lemma: \n",
      ", Dependency: dep\n",
      "Token: I, POS: PRON, Lemma: I, Dependency: nsubj\n",
      "Token: has, POS: VERB, Lemma: have, Dependency: ROOT\n",
      "Token: a, POS: DET, Lemma: a, Dependency: det\n",
      "Token: pen, POS: NOUN, Lemma: pen, Dependency: dobj\n",
      "Token: and, POS: CCONJ, Lemma: and, Dependency: cc\n",
      "Token: he, POS: PRON, Lemma: he, Dependency: nsubj\n",
      "Token: have, POS: VERB, Lemma: have, Dependency: conj\n",
      "Token: a, POS: DET, Lemma: a, Dependency: det\n",
      "Token: notebook, POS: NOUN, Lemma: notebook, Dependency: dobj\n",
      "Token: ., POS: PUNCT, Lemma: ., Dependency: punct\n",
      "Token: My, POS: PRON, Lemma: my, Dependency: poss\n",
      "Token: name, POS: NOUN, Lemma: name, Dependency: nsubj\n",
      "Token: is, POS: AUX, Lemma: be, Dependency: ROOT\n",
      "Token: John, POS: PROPN, Lemma: John, Dependency: attr\n",
      "Token: and, POS: CCONJ, Lemma: and, Dependency: cc\n",
      "Token: I, POS: PRON, Lemma: I, Dependency: nsubj\n",
      "Token: live, POS: VERB, Lemma: live, Dependency: conj\n",
      "Token: in, POS: ADP, Lemma: in, Dependency: prep\n",
      "Token: New, POS: PROPN, Lemma: New, Dependency: compound\n",
      "Token: York, POS: PROPN, Lemma: York, Dependency: pobj\n",
      "Token: ., POS: PUNCT, Lemma: ., Dependency: punct\n",
      "Token: \n",
      ", POS: SPACE, Lemma: \n",
      ", Dependency: dep\n",
      "\n",
      "Thực thể nhận dạng (NER):\n",
      "Entity: John, Label: PERSON\n",
      "Entity: New York, Label: GPE\n",
      "\n",
      "Chi tiết lỗi phát hiện:\n",
      "- Mô tả lỗi: Use third-person verb with ‘He’.\n",
      "  Lỗi: 'are'\n",
      "  Gợi ý sửa: is, was\n",
      "  Vị trí: 4 - 7\n",
      "----------------------------------------\n",
      "- Mô tả lỗi: The pronoun ‘She’ is usually used with a third-person or a past tense verb.\n",
      "  Lỗi: 'go'\n",
      "  Gợi ý sửa: goes, went\n",
      "  Vị trí: 24 - 26\n",
      "----------------------------------------\n",
      "- Mô tả lỗi: ‘Everyday’ is an adjective. Did you mean “every day”?\n",
      "  Lỗi: 'everyday'\n",
      "  Gợi ý sửa: every day\n",
      "  Vị trí: 37 - 45\n",
      "----------------------------------------\n",
      "- Mô tả lỗi: The pronoun ‘I’ must be used with a non-third-person form of a verb.\n",
      "  Lỗi: 'has'\n",
      "  Gợi ý sửa: have\n",
      "  Vị trí: 50 - 53\n",
      "----------------------------------------\n",
      "- Mô tả lỗi: The pronoun ‘he’ is usually used with a third-person or a past tense verb.\n",
      "  Lỗi: 'have'\n",
      "  Gợi ý sửa: has, had\n",
      "  Vị trí: 67 - 71\n",
      "----------------------------------------\n",
      "\n",
      "Văn bản đã được sửa:\n",
      "\n",
      "He is a good boy. She goes to school every day. \n",
      "I have a pen and he has a notebook. My name is John and I live in New York.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from language_tool_python import LanguageTool\n",
    "\n",
    "def analyze_and_correct_text(text):\n",
    "    # Tải mô hình ngôn ngữ tiếng Anh (spaCy)\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Hiển thị thông tin về cấu trúc câu, POS tagging và NER\n",
    "    print(\"Cấu trúc câu và thông tin từ vựng:\")\n",
    "    for token in doc:\n",
    "        print(f\"Token: {token.text}, POS: {token.pos_}, Lemma: {token.lemma_}, Dependency: {token.dep_}\")\n",
    "\n",
    "    print(\"\\nThực thể nhận dạng (NER):\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n",
    "\n",
    "    # Khởi tạo công cụ kiểm tra ngữ pháp (LanguageTool)\n",
    "    tool = LanguageTool('en-US')\n",
    "    matches = tool.check(text)\n",
    "\n",
    "    # Hiển thị thông tin lỗi\n",
    "    print(\"\\nChi tiết lỗi phát hiện:\")\n",
    "    for match in matches:\n",
    "        print(f\"- Mô tả lỗi: {match.message}\")\n",
    "        print(f\"  Lỗi: '{text[match.offset:match.offset + match.errorLength]}'\")\n",
    "        print(f\"  Gợi ý sửa: {', '.join(match.replacements)}\")\n",
    "        print(f\"  Vị trí: {match.offset} - {match.offset + match.errorLength}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # Tự động sửa lỗi\n",
    "    corrected_text = tool.correct(text)\n",
    "\n",
    "    # Hiển thị văn bản sau khi sửa\n",
    "    print(\"\\nVăn bản đã được sửa:\")\n",
    "    print(corrected_text)\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "# Văn bản đầu vào\n",
    "input_text = \"\"\"\n",
    "He are a good boy. She go to school everyday. \n",
    "I has a pen and he have a notebook. My name is John and I live in New York.\n",
    "\"\"\"\n",
    "\n",
    "# Gọi hàm\n",
    "corrected_text = analyze_and_correct_text(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản sau khi tiền xử lý:\n",
      "\n",
      "john is reading a book about artificial intelligence while sitting in the library\n",
      "he found the book very interesting and decided to borrow it\n",
      "\n",
      "\n",
      "--- Phân tích thành phần trong câu ---\n",
      "Phân tích từ loại (POS tagging):\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: john, POS: PROPN\n",
      "Token: is, POS: AUX\n",
      "Token: reading, POS: VERB\n",
      "Token: a, POS: DET\n",
      "Token: book, POS: NOUN\n",
      "Token: about, POS: ADP\n",
      "Token: artificial, POS: ADJ\n",
      "Token: intelligence, POS: NOUN\n",
      "Token: while, POS: SCONJ\n",
      "Token: sitting, POS: VERB\n",
      "Token: in, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: library, POS: NOUN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: he, POS: PRON\n",
      "Token: found, POS: VERB\n",
      "Token: the, POS: DET\n",
      "Token: book, POS: NOUN\n",
      "Token: very, POS: ADV\n",
      "Token: interesting, POS: ADJ\n",
      "Token: and, POS: CCONJ\n",
      "Token: decided, POS: VERB\n",
      "Token: to, POS: PART\n",
      "Token: borrow, POS: VERB\n",
      "Token: it, POS: PRON\n",
      "Token: \n",
      ", POS: SPACE\n",
      "\n",
      "Cụm danh từ (Noun Phrases):\n",
      "- \n",
      "john\n",
      "- a book\n",
      "- artificial intelligence\n",
      "- the library\n",
      "- he\n",
      "- the book\n",
      "- it\n",
      "\n",
      "Cụm động từ (Verb Phrases):\n",
      "- \n",
      " john is reading a book about artificial intelligence\n",
      "- while sitting in the library \n",
      "\n",
      "- \n",
      " john is reading a book about artificial intelligence while sitting in the library \n",
      " he found the book very interesting and decided to borrow it \n",
      "\n",
      "- decided to borrow it \n",
      "\n",
      "- to borrow it \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Tiền xử lý văn bản\n",
    "def preprocess_text(text):\n",
    "    # Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "    # Loại bỏ ký tự không cần thiết (dấu câu, ký hiệu đặc biệt)\n",
    "    import re\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Phân tích thành phần câu\n",
    "def analyze_sentence(text):\n",
    "    # Tải mô hình ngôn ngữ tiếng Anh (spaCy)\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Phân tích câu\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Hiển thị thông tin từ vựng\n",
    "    print(\"Phân tích từ loại (POS tagging):\")\n",
    "    for token in doc:\n",
    "        print(f\"Token: {token.text}, POS: {token.pos_}\")\n",
    "    \n",
    "    # Phát hiện cụm danh từ (Noun Phrases)\n",
    "    print(\"\\nCụm danh từ (Noun Phrases):\")\n",
    "    for np in doc.noun_chunks:\n",
    "        print(f\"- {np.text}\")\n",
    "    \n",
    "    # Phát hiện cụm động từ (Verb Phrases)\n",
    "    print(\"\\nCụm động từ (Verb Phrases):\")\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verb_phrase = \" \".join([child.text for child in token.subtree])\n",
    "            print(f\"- {verb_phrase}\")\n",
    "\n",
    "# Văn bản đầu vào\n",
    "input_text = \"\"\"\n",
    "John is reading a book about artificial intelligence while sitting in the library.\n",
    "He found the book very interesting and decided to borrow it.\n",
    "\"\"\"\n",
    "\n",
    "# Tiền xử lý văn bản\n",
    "cleaned_text = preprocess_text(input_text)\n",
    "print(\"Văn bản sau khi tiền xử lý:\")\n",
    "print(cleaned_text)\n",
    "\n",
    "# Phân tích thành phần câu\n",
    "print(\"\\n--- Phân tích thành phần trong câu ---\")\n",
    "analyze_sentence(cleaned_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
